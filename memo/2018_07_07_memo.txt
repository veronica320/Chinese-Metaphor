CCL2018@Tsinghua 2018.07.07会议纪要


一. 训练测试数据调整与分割

由于原始数据中，标签以index的形式存储，不方便我们直观地分析结果，已将index替换为文字标签（e.g., '1' --> '乐'）。

为了保持后续模型优化过程中评价的一致性，将数据集按9:1分割，之后的实验训练集与测试集保持不变：
	动名词分类：训练集为verb_train.txt（N=3955），测试集为verb_test.txt（N=439）
	情感分类：训练集为emo_train.txt（N=3267），测试集为emo_test.txt（N=363）

具体数据请见data_CCL2018.zip。


二. Baseline模型

我们采用的Baseline模型基本结构为：两层CNN+一层双向GRU。具体可见模型结构图。

目前，在没有任何外部语料与特征工程的情况下，emo上的准确率38.6%, verb为72.2%。结果与基本的分析请见baseline_result.zip。

###########希望同学们多花时间看看结果里的badcase，总结误判的句子类型、特点，以及改进方法。###########


三. 模型优化

目前汇总的候选特征：
	1. 通过back_translaton将原始语料进行扩充，以获得外部翻译模型学到的同义词、句式结构改写等方面的信息；
	2. 通过WordNet等外部资源，将动词、名词的subcategory作为feature加入模型；
	3. 将句子各部分的句法依存关系作为feature加入模型；
	4. 字词向量的拼接以及使用预训练的字词向量（需要用到外部预料，最好是开源的中文比喻句语料）；
	5. 通过观察数据，考察虚词在两个子任务中起到的作用，再决定将虚词的哪些信息加入模型。

模型结构方面，计划尝试：
	1. 直接使用Embedding作为分类特征（参考'Baseline Needs More Love: On Simple Word-Embedding-Based Models and Associated Pooling Mechanisms'一文）；
	2. 使用Transformer最为sentence encoder（参见'Attention Is All You Need'一文)。


四. 下周任务

	1. 继续思考哪些特征可以用来帮助隐喻的探测与情感分类（可以通过：观察数据、读论文、拍脑门等方式）。示例请参见以上的候选特征。有想法请随时在群里提出；
	2. 观察数据，以及baseline的结果，分析数据特征（e.g., 模型误判的可能原因、各类隐喻的分布及语言学特征等）、



